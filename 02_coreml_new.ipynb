{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch as th\n",
    "import coremltools as ct\n",
    "import diffusers\n",
    "\n",
    "from pathlib import Path\n",
    "from diffusers import StableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get this into coreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pipe.unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coremltools.converters.mil import Builder as mb\n",
    "from coremltools.converters.mil.frontend.torch.torch_op_registry import register_torch_op, _TORCH_OPS_REGISTRY\n",
    "import coremltools.converters.mil.frontend.torch.ops as cml_ops\n",
    "\n",
    "# you don't need this block on master of diffuser\n",
    "# def unsliced_attention(self, query, key, value, _sequence_length, _dim):\n",
    "#     attn = (torch.einsum(\"b i d, b j d -> b i j\", query, key) * self.scale).softmax(dim=-1)\n",
    "#     attn = torch.einsum(\"b i j, b j d -> b i d\", attn, value)\n",
    "#     return self.reshape_batch_dim_to_heads(attn)\n",
    "# diffusers.models.attention.CrossAttention._attention = unsliced_attention\n",
    "\n",
    "orig_einsum = th.einsum\n",
    "def fake_einsum(a, b, c):\n",
    "    \"coreml does not like einsum, so let's replace the 2 uses of them\"\n",
    "    if a == 'b i d, b j d -> b i j': return th.bmm(b, c.permute(0, 2, 1))\n",
    "    if a == 'b i j, b j d -> b i d': return th.bmm(b, c)\n",
    "    raise ValueError(f\"unsupported einsum {a} on {b.shape} {c.shape}\")\n",
    "    \n",
    "th.einsum = fake_einsum\n",
    "\n",
    "if \"broadcast_to\" in _TORCH_OPS_REGISTRY: del _TORCH_OPS_REGISTRY[\"broadcast_to\"]\n",
    "@register_torch_op\n",
    "def broadcast_to(context, node): return cml_ops.expand(context, node)\n",
    "if \"gelu\" in _TORCH_OPS_REGISTRY: del _TORCH_OPS_REGISTRY[\"gelu\"]\n",
    "@register_torch_op\n",
    "def gelu(context, node): context.add(mb.gelu(x=context[node.inputs[0]], name=node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Undictifier(th.nn.Module):\n",
    "    \"A simple class to undict the forward method\"\n",
    "    def __init__(self, m):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "    def forward(self, *args, **kwargs): return self.m(*args, **kwargs)[\"sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uf = Undictifier(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of the exported model\n",
    "out_name=\"unet.mlpackage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we need to trace it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tracing\")\n",
    "f_trace = th.jit.trace(uf, (th.zeros(2, 4, 64, 64), th.zeros(1), th.zeros(2, 77, 768)), strict=False, check_trace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's also convert it to mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"converting\")\n",
    "f_coreml_fp16 = ct.convert(f_trace, \n",
    "           inputs=[ct.TensorType(shape=(2, 4, 64, 64)), ct.TensorType(shape=(1,)), ct.TensorType(shape=(2, 77, 768))],\n",
    "           convert_to=\"mlprogram\",  compute_precision=ct.precision.FLOAT16, skip_model_load=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and save!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_coreml_fp16.save(f\"{out_name}\")\n",
    "th.einsum = orig_einsum\n",
    "print(\"the deed is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual trick is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetWrapper:\n",
    "    def __init__(self, f, out_name=\"unet.mlpackage\"):\n",
    "        self.in_channels = f.in_channels\n",
    "        if not Path(out_name).exists():\n",
    "            print(\"generating coreml model\"); generate_coreml_model_via_awful_hacks(f, out_name); print(\"saved\")\n",
    "        # not only does ANE take forever to load because it recompiles each time - it then doesn't work!\n",
    "        # and NSLocalizedDescription = \"Error computing NN outputs.\"; is not helpful... GPU it is\n",
    "        print(\"loading saved coreml model\"); f_coreml_fp16 = ct.models.MLModel(out_name, compute_units=ct.ComputeUnit.CPU_AND_GPU); print(\"loaded\")\n",
    "        self.f = f_coreml_fp16\n",
    "    def __call__(self, sample, timestep, encoder_hidden_states):\n",
    "        args = {\"sample_1\": sample.numpy(), \"timestep\": th.tensor([timestep], dtype=th.int32).numpy(), \"input_35\": encoder_hidden_states.numpy()}\n",
    "        for v in self.f.predict(args).values():\n",
    "            return diffusers.models.unet_2d_condition.UNet2DConditionOutput(sample=th.tensor(v, dtype=th.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we replace the unet model with this monster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe.safety_checker = lambda images, **kwargs: (images, False)\n",
    "pipe.unet = UNetWrapper(pipe.unet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "890fe30c5fafa3a5c10db77cd77a4c597395c40b14892f38f156d03349e2a976"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
